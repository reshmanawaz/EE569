{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-UTNUhyQSeV"
      },
      "outputs": [],
      "source": [
        "#working fashion mnist\n",
        "# Fashion MNIST Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "train_batch_size = 64\n",
        "test_batch_size = 1000\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Net, self).__init__()\n",
        "       self.conv1 = nn.Conv2d(1, 6, 5, stride=1, padding=2)\n",
        "       self.conv2 = nn.Conv2d(6, 16, 5, stride=1, padding=0)\n",
        "       self.fc1 = nn.Linear(16*5*5, 120)\n",
        "       self.fc2 = nn.Linear(120, 84)\n",
        "       self.fc3 = nn.Linear(84, 10)  # Change from 10 to 10 for Fashion-MNIST\n",
        "   def forward(self, x):\n",
        "       x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "       x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "       x = x.view(-1, self.num_flat_features(x))\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "   def num_flat_features(self, x):\n",
        "       x_size = x.size()[1:]\n",
        "       num = 1\n",
        "       for n in x_size:\n",
        "           num *= n\n",
        "       return num\n",
        "\n",
        "def load_data():\n",
        "   transform = transforms.Compose([\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.5,), (0.5,))  # Adjust normalization for Fashion-MNIST\n",
        "   ])\n",
        "   train_set = tv.datasets.FashionMNIST(\n",
        "       root='./data',\n",
        "       train=True,\n",
        "       download=True,\n",
        "       transform=transform\n",
        "   )\n",
        "   train_loader = torch.utils.data.DataLoader(\n",
        "       train_set,\n",
        "       batch_size=train_batch_size,\n",
        "       shuffle=True,\n",
        "       num_workers=2\n",
        "   )\n",
        "   test_set = tv.datasets.FashionMNIST(\n",
        "       root='./data',\n",
        "       train=False,\n",
        "       download=True,\n",
        "       transform=transform\n",
        "   )\n",
        "   test_loader = torch.utils.data.DataLoader(\n",
        "       test_set,\n",
        "       batch_size=test_batch_size,\n",
        "       shuffle=False,\n",
        "       num_workers=2\n",
        "   )\n",
        "   print(\"Data loaded successfully...\")\n",
        "   return train_loader, test_loader\n",
        "\n",
        "def accuracy(model, x):\n",
        "   with torch.no_grad():\n",
        "       correct = 0\n",
        "       total = 0\n",
        "       for data in x:\n",
        "           images, labels = data\n",
        "           outputs = model(images)\n",
        "           _, predicted = torch.max(outputs.data, 1)\n",
        "           total += labels.size(0)\n",
        "           correct += (predicted == labels).sum().item()\n",
        "\n",
        "       return (100 * correct / total)\n",
        "\n",
        "def train(train_loader, test_loader, model, criterion, optimizer, epoch):\n",
        "   model.train()\n",
        "   running_loss = 0\n",
        "   for i, data in enumerate(train_loader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = model(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "\n",
        "       running_loss += loss.item()\n",
        "       if i % 200 == 199:\n",
        "           print(\"[epoch %d, iter %5d] loss: %.3f\" % (epoch+1, i+1, running_loss / 200))\n",
        "           running_loss = 0.0\n",
        "   train_acc = accuracy(model, train_loader)\n",
        "   test_acc = accuracy(model, test_loader)\n",
        "   print(\"epoch %d: train_acc %.3f, test_acc %.3f\" % (epoch+1, train_acc, test_acc))\n",
        "   return train_acc, test_acc\n",
        "\n",
        "def display(train_acc, test_acc):\n",
        "   fig, ax = plt.subplots()\n",
        "   ax.plot(range(1, len(train_acc) + 1), train_acc, color='r', label='train_acc')\n",
        "   ax.plot(range(1, len(test_acc) + 1), test_acc, color='b', label='test_acc')\n",
        "   ax.legend(loc='lower right')\n",
        "   plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   # input Fashion-MNIST\n",
        "   train_loader, test_loader = load_data()\n",
        "   # new model\n",
        "   net = Net()\n",
        "\n",
        "   # training\n",
        "   learning_rate = 0.001\n",
        "   momentum = 0.9\n",
        "   max_epoch = 20\n",
        "   criterion = nn.CrossEntropyLoss()\n",
        "   optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "   train_acc = []\n",
        "   test_acc = []\n",
        "   for epoch in range(max_epoch):\n",
        "       train_acc_t, test_acc_t = train(train_loader, test_loader, net, criterion, optimizer, epoch)\n",
        "       train_acc.append(train_acc_t)\n",
        "       test_acc.append(test_acc_t)\n",
        "\n",
        "   display(train_acc, test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EE569 Homework Assignment #5 Sample Code\n",
        "# requirements: python3 + pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "train_batch_size=64\n",
        "test_batch_size=1000\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv1=nn.Conv2d(1,6,5,stride=1,padding=2)\n",
        "        self.conv2=nn.Conv2d(6,16,5,stride=1,padding=0)\n",
        "        self.fc1=nn.Linear(16*5*5,120)\n",
        "        self.fc2=nn.Linear(120,84)\n",
        "        self.fc3=nn.Linear(84,10)\n",
        "    def forward(self,x):\n",
        "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "        x=x.view(-1,self.num_flat_features(x))\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.relu(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "    def num_flat_features(self,x):\n",
        "        #x is a 4D tensor\n",
        "        x_size=x.size()[1:]\n",
        "        num=1\n",
        "        for n in x_size:\n",
        "            num*=n\n",
        "        return num\n",
        "\n",
        "def load_data():\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_set=tv.datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "        )\n",
        "    train_loader=torch.utils.data.DataLoader(\n",
        "        train_set,\n",
        "        batch_size=train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "    test_set=tv.datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "        )\n",
        "    test_loader=torch.utils.data.DataLoader(\n",
        "        test_set,\n",
        "        batch_size=test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2)\n",
        "    print(\"data loaded successfully...\")\n",
        "    return train_loader,test_loader\n",
        "\n",
        "def accuracy(model,x,neg=False):\n",
        "    with torch.no_grad():\n",
        "        correct=0\n",
        "        total=0\n",
        "        class_correct = list(0. for i in range(10))\n",
        "        class_total = list(0. for i in range(10))\n",
        "        for data in x:\n",
        "            images,labels=data\n",
        "            if neg:\n",
        "              images=-images\n",
        "            images,labels=images, labels\n",
        "            outputs=model(images)\n",
        "            _,predicted=torch.max(outputs.data,1)\n",
        "            total+=labels.size(0)\n",
        "            correct+=(predicted==labels).sum().item()\n",
        "\n",
        "        return (100 * correct / total)\n",
        "\n",
        "def train(train_loader, test_loader, model, criterion, optimizer,epoch):\n",
        "    model.train()\n",
        "    running_loss=0\n",
        "    for i,data in enumerate(train_loader,0):\n",
        "        inputs,labels=data\n",
        "        inputs,labels=inputs, labels\n",
        "        optimizer.zero_grad()\n",
        "        outputs=net(inputs)\n",
        "        loss=criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss+=loss.item()\n",
        "        if i%200==199:\n",
        "            print(\"[epoch %d, iter %5d] loss: %.3f\"%(epoch+1,i+1,running_loss/200))\n",
        "            running_loss=0.0\n",
        "    train_acc=accuracy(model,train_loader)\n",
        "    test_acc=accuracy(model,test_loader)\n",
        "    print(\"epoch %d: train_acc %.3f, test_acc %.3f\"%(epoch+1,train_acc,test_acc))\n",
        "    return train_acc,test_acc\n",
        "\n",
        "def display(train_acc,test_acc):\n",
        "    fig,ax=plt.subplots()\n",
        "    ax.plot(range(1,len(train_acc)+1),train_acc,color='r',label='train_acc')\n",
        "    ax.plot(range(1,len(test_acc)+1),test_acc,color='b',label='test_acc')\n",
        "    ax.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # input MNIST\n",
        "    train_loader,test_loader=load_data()\n",
        "    # new model\n",
        "    net=Net()\n",
        "\n",
        "    # training\n",
        "    learning_rate=0.01\n",
        "    momentum=0.9\n",
        "    max_epoch=10\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    optimizer=optim.SGD(net.parameters(),lr=learning_rate,momentum=momentum)\n",
        "\n",
        "    train_acc=[]\n",
        "    test_acc=[]\n",
        "    for epoch in range(max_epoch):\n",
        "        train_acc_t,test_acc_t=train(train_loader, test_loader, net, criterion, optimizer,epoch)\n",
        "        train_acc.append(train_acc_t)\n",
        "        test_acc.append(test_acc_t)\n",
        "\n",
        "    display(train_acc,test_acc)"
      ],
      "metadata": {
        "id": "yM12DO0bR9ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "train_batch_size = 64\n",
        "test_batch_size = 1000\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Net, self).__init__()\n",
        "       self.conv1 = nn.Conv2d(3, 6, 5)  # Adjust input channels to 3 for CIFAR-10\n",
        "       self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "       self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "       self.fc2 = nn.Linear(120, 84)\n",
        "       self.fc3 = nn.Linear(84, 10)  # Adjust output to 10 for CIFAR-10\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "       x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "       x = x.view(-1, self.num_flat_features(x))\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "   def num_flat_features(self, x):\n",
        "       size = x.size()[1:]\n",
        "       num_features = 1\n",
        "       for s in size:\n",
        "           num_features *= s\n",
        "       return num_features\n",
        "\n",
        "def load_data():\n",
        "   transform = transforms.Compose([\n",
        "       transforms.Resize((32, 32)),  # Resize images to 32x32 for CIFAR-10\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Adjust normalization for CIFAR-10\n",
        "   ])\n",
        "   train_set = tv.datasets.CIFAR10(\n",
        "       root='./data',\n",
        "       train=True,\n",
        "       download=True,\n",
        "       transform=transform\n",
        "   )\n",
        "   train_loader = torch.utils.data.DataLoader(\n",
        "       train_set,\n",
        "       batch_size=train_batch_size,\n",
        "       shuffle=True,\n",
        "       num_workers=2\n",
        "   )\n",
        "   test_set = tv.datasets.CIFAR10(\n",
        "       root='./data',\n",
        "       train=False,\n",
        "       download=True,\n",
        "       transform=transform\n",
        "   )\n",
        "   test_loader = torch.utils.data.DataLoader(\n",
        "       test_set,\n",
        "       batch_size=test_batch_size,\n",
        "       shuffle=False,\n",
        "       num_workers=2\n",
        "   )\n",
        "   print(\"Data loaded successfully...\")\n",
        "   return train_loader, test_loader\n",
        "\n",
        "def accuracy(model, data_loader):\n",
        "   with torch.no_grad():\n",
        "       correct = 0\n",
        "       total = 0\n",
        "       for data in data_loader:\n",
        "           images, labels = data\n",
        "           outputs = model(images)\n",
        "           _, predicted = torch.max(outputs.data, 1)\n",
        "           total += labels.size(0)\n",
        "           correct += (predicted == labels).sum().item()\n",
        "\n",
        "   return (100 * correct / total)\n",
        "\n",
        "def train(train_loader, test_loader, model, criterion, optimizer, scheduler, max_epoch):\n",
        "   train_acc = []\n",
        "   test_acc = []\n",
        "   for epoch in range(max_epoch):\n",
        "       model.train()\n",
        "       running_loss = 0\n",
        "       for i, data in enumerate(train_loader, 0):\n",
        "           inputs, labels = data\n",
        "           optimizer.zero_grad()\n",
        "           outputs = model(inputs)\n",
        "           loss = criterion(outputs, labels)\n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "\n",
        "           running_loss += loss.item()\n",
        "           if i % 200 == 199:\n",
        "               print(\"[epoch %d, iter %5d] loss: %.3f\" % (epoch+1, i+1, running_loss / 200))\n",
        "               running_loss = 0.0\n",
        "\n",
        "\n",
        "       # Update learning rate\n",
        "       scheduler.step()\n",
        "\n",
        "       train_acc_epoch = accuracy(model, train_loader)\n",
        "       test_acc_epoch = accuracy(model, test_loader)\n",
        "       train_acc.append(train_acc_epoch)\n",
        "       test_acc.append(test_acc_epoch)\n",
        "       print(\"epoch %d: train_acc %.3f, test_acc %.3f\" % (epoch+1, train_acc_epoch, test_acc_epoch))\n",
        "\n",
        "   return train_acc, test_acc\n",
        "\n",
        "def display(train_acc, test_acc):\n",
        "   fig, ax = plt.subplots()\n",
        "   ax.plot(range(1, len(train_acc) + 1), train_acc, color='r', label='train_acc')\n",
        "   ax.plot(range(1, len(test_acc) + 1), test_acc, color='b', label='test_acc')\n",
        "   ax.legend(loc='lower right')\n",
        "   plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   # Input CIFAR-10\n",
        "   train_loader, test_loader = load_data()\n",
        "   # New model\n",
        "   net = Net()\n",
        "\n",
        "   # Training\n",
        "   learning_rate = 0.0008\n",
        "   max_epoch = 30\n",
        "   criterion = nn.CrossEntropyLoss()\n",
        "   #optimizer = optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "   optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999))  # You can adjust the betas parameter for momentum\n",
        "\n",
        " #Learning rate scheduler\n",
        "   step_size = 15  # Step size for learning rate decay\n",
        "   gamma = 0.1     # Multiplicative factor for learning rate decay\n",
        "   scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "   train_acc, test_acc = train(train_loader, test_loader, net, criterion, optimizer, scheduler, max_epoch)\n",
        "\n",
        "   display(train_acc, test_acc)"
      ],
      "metadata": {
        "id": "t_biTUiLRqwC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
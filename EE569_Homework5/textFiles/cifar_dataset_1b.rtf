{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red89\green156\blue62;\red23\green23\blue23;\red202\green202\blue202;
\red183\green111\blue179;\red167\green197\blue152;\red70\green137\blue204;\red67\green192\blue160;\red212\green212\blue212;
\red212\green214\blue154;\red140\green211\blue254;\red113\green184\blue255;\red194\green126\blue101;}
{\*\expandedcolortbl;;\cssrgb\c41569\c66275\c30980;\cssrgb\c11765\c11765\c11765;\cssrgb\c83137\c83137\c83137;
\cssrgb\c77255\c52549\c75294;\cssrgb\c70980\c80784\c65882;\cssrgb\c33725\c61176\c83922;\cssrgb\c30588\c78824\c69020;\cssrgb\c86275\c86275\c86275;
\cssrgb\c86275\c86275\c66667;\cssrgb\c61176\c86275\c99608;\cssrgb\c50980\c77647\c100000;\cssrgb\c80784\c56863\c47059;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 # CIFAR-10 Dataset\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.nn \cf5 \strokec5 as\cf4 \strokec4  nn\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.nn.functional \cf5 \strokec5 as\cf4 \strokec4  F\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.optim \cf5 \strokec5 as\cf4 \strokec4  optim\cf4 \cb1 \strokec4 \
\
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torchvision \cf5 \strokec5 as\cf4 \strokec4  tv\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torchvision.transforms \cf5 \strokec5 as\cf4 \strokec4  transforms\cf4 \cb1 \strokec4 \
\
\cf5 \cb3 \strokec5 import\cf4 \strokec4  matplotlib.pyplot \cf5 \strokec5 as\cf4 \strokec4  plt\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  numpy \cf5 \strokec5 as\cf4 \strokec4  np\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  math\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  os\cf4 \cb1 \strokec4 \
\
\cf5 \cb3 \strokec5 from\cf4 \strokec4  torch.optim.lr_scheduler \cf5 \strokec5 import\cf4 \strokec4  StepLR\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4 train_batch_size = \cf6 \strokec6 64\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4 test_batch_size = \cf6 \strokec6 1000\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 Net\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 __init__\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        super\cf9 \strokec9 (\cf4 \strokec4 Net\cf9 \strokec9 ,\cf4 \strokec4  \cf11 \strokec11 self\cf9 \strokec9 )\cf4 \strokec4 .\cf10 \strokec10 __init__\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf11 \strokec11 self\cf4 \strokec4 .conv1 = nn.Conv2d\cf9 \strokec9 (\cf6 \strokec6 3\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 6\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 5\cf9 \strokec9 )\cf4 \strokec4   \cf2 \strokec2 # Adjust input channels to 3 for CIFAR-10\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf11 \strokec11 self\cf4 \strokec4 .conv2 = nn.Conv2d\cf9 \strokec9 (\cf6 \strokec6 6\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 16\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 5\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf11 \strokec11 self\cf4 \strokec4 .fc1 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 16\cf4 \strokec4  * \cf6 \strokec6 5\cf4 \strokec4  * \cf6 \strokec6 5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 120\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf11 \strokec11 self\cf4 \strokec4 .fc2 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 120\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 84\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf11 \strokec11 self\cf4 \strokec4 .fc3 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 84\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 10\cf9 \strokec9 )\cf4 \strokec4   \cf2 \strokec2 # Adjust output to 10 for CIFAR-10\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 forward\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 , \cf11 \strokec11 x\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = F.max_pool2d\cf9 \strokec9 (\cf4 \strokec4 F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .conv1\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )),\cf4 \strokec4  \cf6 \strokec6 2\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = F.max_pool2d\cf9 \strokec9 (\cf4 \strokec4 F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .conv2\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )),\cf4 \strokec4  \cf6 \strokec6 2\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = x.view\cf9 \strokec9 (\cf6 \strokec6 -1\cf9 \strokec9 ,\cf4 \strokec4  \cf11 \strokec11 self\cf4 \strokec4 .num_flat_features\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .fc1\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .fc2\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        x = \cf11 \strokec11 self\cf4 \strokec4 .fc3\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf5 \strokec5 return\cf4 \strokec4  x\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 num_flat_features\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 , \cf11 \strokec11 x\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        size = x.size\cf9 \strokec9 ()[\cf6 \strokec6 1\cf9 \strokec9 :]\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        num_features = \cf6 \strokec6 1\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf5 \strokec5 for\cf4 \strokec4  s \cf12 \strokec12 in\cf4 \strokec4  size\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            num_features *= s\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf5 \strokec5 return\cf4 \strokec4  num_features\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 load_data\cf4 \strokec4 ()\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    transform = transforms.Compose\cf9 \strokec9 ([\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        transforms.Resize\cf9 \strokec9 ((\cf6 \strokec6 32\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 32\cf9 \strokec9 )),\cf4 \strokec4   \cf2 \strokec2 # Resize images to 32x32 for CIFAR-10\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        transforms.ToTensor\cf9 \strokec9 (),\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        transforms.Normalize\cf9 \strokec9 ((\cf6 \strokec6 0.5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0.5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0.5\cf9 \strokec9 ),\cf4 \strokec4  \cf9 \strokec9 (\cf6 \strokec6 0.5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0.5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0.5\cf9 \strokec9 ))\cf4 \strokec4   \cf2 \strokec2 # Adjust normalization for CIFAR-10\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf9 \strokec9 ])\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    train_set = tv.datasets.CIFAR10\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        root=\cf13 \strokec13 './data'\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        train=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        download=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        transform=transform\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    train_loader = torch.utils.data.DataLoader\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        train_set\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        batch_size=train_batch_size\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        shuffle=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        num_workers=\cf6 \strokec6 2\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    test_set = tv.datasets.CIFAR10\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        root=\cf13 \strokec13 './data'\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        train=\cf7 \strokec7 False\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        download=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        transform=transform\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    test_loader = torch.utils.data.DataLoader\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        test_set\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        batch_size=test_batch_size\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        shuffle=\cf7 \strokec7 False\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        num_workers=\cf6 \strokec6 2\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "Data loaded successfully..."\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf5 \strokec5 return\cf4 \strokec4  train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 accuracy\cf4 \strokec4 (\cf11 \strokec11 model\cf4 \strokec4 , \cf11 \strokec11 data_loader\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    \cf5 \strokec5 with\cf4 \strokec4  torch.no_grad\cf9 \strokec9 ():\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        correct = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        total = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf5 \strokec5 for\cf4 \strokec4  data \cf12 \strokec12 in\cf4 \strokec4  data_loader\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            images\cf9 \strokec9 ,\cf4 \strokec4  labels = data\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            outputs = model\cf9 \strokec9 (\cf4 \strokec4 images\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            _\cf9 \strokec9 ,\cf4 \strokec4  predicted = torch.\cf10 \strokec10 max\cf9 \strokec9 (\cf4 \strokec4 outputs.data\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 1\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            total += labels.size\cf9 \strokec9 (\cf6 \strokec6 0\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            correct += \cf9 \strokec9 (\cf4 \strokec4 predicted == labels\cf9 \strokec9 )\cf4 \strokec4 .\cf10 \strokec10 sum\cf9 \strokec9 ()\cf4 \strokec4 .item\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    \cf5 \strokec5 return\cf4 \strokec4  \cf9 \strokec9 (\cf6 \strokec6 100\cf4 \strokec4  * correct / total\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 train\cf4 \strokec4 (\cf11 \strokec11 train_loader\cf4 \strokec4 , \cf11 \strokec11 test_loader\cf4 \strokec4 , \cf11 \strokec11 model\cf4 \strokec4 , \cf11 \strokec11 criterion\cf4 \strokec4 , \cf11 \strokec11 optimizer\cf4 \strokec4 , \cf11 \strokec11 scheduler\cf4 \strokec4 , \cf11 \strokec11 max_epoch\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    train_acc = \cf9 \strokec9 []\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    test_acc = \cf9 \strokec9 []\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf5 \strokec5 for\cf4 \strokec4  epoch \cf12 \strokec12 in\cf4 \strokec4  \cf10 \strokec10 range\cf9 \strokec9 (\cf4 \strokec4 max_epoch\cf9 \strokec9 ):\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        model.train\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        running_loss = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf5 \strokec5 for\cf4 \strokec4  i\cf9 \strokec9 ,\cf4 \strokec4  data \cf12 \strokec12 in\cf4 \strokec4  \cf10 \strokec10 enumerate\cf9 \strokec9 (\cf4 \strokec4 train_loader\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0\cf9 \strokec9 ):\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            inputs\cf9 \strokec9 ,\cf4 \strokec4  labels = data\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            optimizer.zero_grad\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            outputs = model\cf9 \strokec9 (\cf4 \strokec4 inputs\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            loss = criterion\cf9 \strokec9 (\cf4 \strokec4 outputs\cf9 \strokec9 ,\cf4 \strokec4  labels\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            loss.backward\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            optimizer.step\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4            running_loss += loss.item\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4            \cf5 \strokec5 if\cf4 \strokec4  i % \cf6 \strokec6 200\cf4 \strokec4  == \cf6 \strokec6 199\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4                \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "[epoch %d, iter %5d] loss: %.3f"\cf4 \strokec4  % \cf9 \strokec9 (\cf4 \strokec4 epoch+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  i+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  running_loss / \cf6 \strokec6 200\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4                running_loss = \cf6 \strokec6 0.0\cf4 \cb1 \strokec4 \
\
\
\cf4 \cb3 \strokec4        \cf2 \strokec2 # Update learning rate\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        scheduler.step\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4        train_acc_epoch = accuracy\cf9 \strokec9 (\cf4 \strokec4 model\cf9 \strokec9 ,\cf4 \strokec4  train_loader\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        test_acc_epoch = accuracy\cf9 \strokec9 (\cf4 \strokec4 model\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        train_acc.append\cf9 \strokec9 (\cf4 \strokec4 train_acc_epoch\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        test_acc.append\cf9 \strokec9 (\cf4 \strokec4 test_acc_epoch\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4        \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "epoch %d: train_acc %.3f, test_acc %.3f"\cf4 \strokec4  % \cf9 \strokec9 (\cf4 \strokec4 epoch+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  train_acc_epoch\cf9 \strokec9 ,\cf4 \strokec4  test_acc_epoch\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    \cf5 \strokec5 return\cf4 \strokec4  train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 display\cf4 \strokec4 (\cf11 \strokec11 train_acc\cf4 \strokec4 , \cf11 \strokec11 test_acc\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    fig\cf9 \strokec9 ,\cf4 \strokec4  ax = plt.subplots\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    ax.plot\cf9 \strokec9 (\cf10 \strokec10 range\cf9 \strokec9 (\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  \cf10 \strokec10 len\cf9 \strokec9 (\cf4 \strokec4 train_acc\cf9 \strokec9 )\cf4 \strokec4  + \cf6 \strokec6 1\cf9 \strokec9 ),\cf4 \strokec4  train_acc\cf9 \strokec9 ,\cf4 \strokec4  color=\cf13 \strokec13 'r'\cf9 \strokec9 ,\cf4 \strokec4  label=\cf13 \strokec13 'train_acc'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    ax.plot\cf9 \strokec9 (\cf10 \strokec10 range\cf9 \strokec9 (\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  \cf10 \strokec10 len\cf9 \strokec9 (\cf4 \strokec4 test_acc\cf9 \strokec9 )\cf4 \strokec4  + \cf6 \strokec6 1\cf9 \strokec9 ),\cf4 \strokec4  test_acc\cf9 \strokec9 ,\cf4 \strokec4  color=\cf13 \strokec13 'b'\cf9 \strokec9 ,\cf4 \strokec4  label=\cf13 \strokec13 'test_acc'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    ax.legend\cf9 \strokec9 (\cf4 \strokec4 loc=\cf13 \strokec13 'lower right'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    plt.show\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 if\cf4 \strokec4  \cf11 \strokec11 __name__\cf4 \strokec4  == \cf13 \strokec13 '__main__'\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 \strokec4    \cf2 \strokec2 # Input CIFAR-10\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader = load_data\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf2 \strokec2 # New model\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    net = Net\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    \cf2 \strokec2 # Training\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    learning_rate = \cf6 \strokec6 0.0008\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    max_epoch = \cf6 \strokec6 30\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    criterion = nn.CrossEntropyLoss\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    \cf2 \strokec2 #optimizer = optimizer = optim.Adam(net.parameters(), lr=learning_rate)\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    optimizer = optim.Adam\cf9 \strokec9 (\cf4 \strokec4 net.parameters\cf9 \strokec9 (),\cf4 \strokec4  lr=learning_rate\cf9 \strokec9 ,\cf4 \strokec4  betas=\cf9 \strokec9 (\cf6 \strokec6 0.9\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0.999\cf9 \strokec9 ))\cf4 \strokec4   \cf2 \strokec2 # You can adjust the betas parameter for momentum\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4  \cf2 \strokec2 #Learning rate scheduler\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    step_size = \cf6 \strokec6 15\cf4 \strokec4   \cf2 \strokec2 # Step size for learning rate decay\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    gamma = \cf6 \strokec6 0.1\cf4 \strokec4      \cf2 \strokec2 # Multiplicative factor for learning rate decay\cf4 \cb1 \strokec4 \
\cf4 \cb3 \strokec4    scheduler = StepLR\cf9 \strokec9 (\cf4 \strokec4 optimizer\cf9 \strokec9 ,\cf4 \strokec4  step_size=step_size\cf9 \strokec9 ,\cf4 \strokec4  gamma=gamma\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc = train\cf9 \strokec9 (\cf4 \strokec4 train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cf9 \strokec9 ,\cf4 \strokec4  net\cf9 \strokec9 ,\cf4 \strokec4  criterion\cf9 \strokec9 ,\cf4 \strokec4  optimizer\cf9 \strokec9 ,\cf4 \strokec4  scheduler\cf9 \strokec9 ,\cf4 \strokec4  max_epoch\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\cf4 \cb3 \strokec4    display\cf9 \strokec9 (\cf4 \strokec4 train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
}
{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red89\green156\blue62;\red23\green23\blue23;\red202\green202\blue202;
\red183\green111\blue179;\red167\green197\blue152;\red70\green137\blue204;\red67\green192\blue160;\red212\green212\blue212;
\red212\green214\blue154;\red140\green211\blue254;\red113\green184\blue255;\red194\green126\blue101;}
{\*\expandedcolortbl;;\cssrgb\c41569\c66275\c30980;\cssrgb\c11765\c11765\c11765;\cssrgb\c83137\c83137\c83137;
\cssrgb\c77255\c52549\c75294;\cssrgb\c70980\c80784\c65882;\cssrgb\c33725\c61176\c83922;\cssrgb\c30588\c78824\c69020;\cssrgb\c86275\c86275\c86275;
\cssrgb\c86275\c86275\c66667;\cssrgb\c61176\c86275\c99608;\cssrgb\c50980\c77647\c100000;\cssrgb\c80784\c56863\c47059;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 #working fashion mnist\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 # Fashion MNIST Dataset\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.nn \cf5 \strokec5 as\cf4 \strokec4  nn\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.nn.functional \cf5 \strokec5 as\cf4 \strokec4  F\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.optim \cf5 \strokec5 as\cf4 \strokec4  optim\cb1 \
\
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torchvision \cf5 \strokec5 as\cf4 \strokec4  tv\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torchvision.transforms \cf5 \strokec5 as\cf4 \strokec4  transforms\cb1 \
\
\cf5 \cb3 \strokec5 import\cf4 \strokec4  matplotlib.pyplot \cf5 \strokec5 as\cf4 \strokec4  plt\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  numpy \cf5 \strokec5 as\cf4 \strokec4  np\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  math\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  os\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 train_batch_size = \cf6 \strokec6 64\cf4 \cb1 \strokec4 \
\cb3 test_batch_size = \cf6 \strokec6 1000\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 Net\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 __init__\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3        super\cf9 \strokec9 (\cf4 \strokec4 Net\cf9 \strokec9 ,\cf4 \strokec4  \cf11 \strokec11 self\cf9 \strokec9 )\cf4 \strokec4 .\cf10 \strokec10 __init__\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3        \cf11 \strokec11 self\cf4 \strokec4 .conv1 = nn.Conv2d\cf9 \strokec9 (\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 6\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 5\cf9 \strokec9 ,\cf4 \strokec4  stride=\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  padding=\cf6 \strokec6 2\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        \cf11 \strokec11 self\cf4 \strokec4 .conv2 = nn.Conv2d\cf9 \strokec9 (\cf6 \strokec6 6\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 16\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 5\cf9 \strokec9 ,\cf4 \strokec4  stride=\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  padding=\cf6 \strokec6 0\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        \cf11 \strokec11 self\cf4 \strokec4 .fc1 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 16\cf4 \strokec4 *\cf6 \strokec6 5\cf4 \strokec4 *\cf6 \strokec6 5\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 120\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        \cf11 \strokec11 self\cf4 \strokec4 .fc2 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 120\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 84\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        \cf11 \strokec11 self\cf4 \strokec4 .fc3 = nn.Linear\cf9 \strokec9 (\cf6 \strokec6 84\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 10\cf9 \strokec9 )\cf4 \strokec4   \cf2 \strokec2 # Change from 10 to 10 for Fashion-MNIST\cf4 \cb1 \strokec4 \
\cb3    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 forward\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 , \cf11 \strokec11 x\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3        x = F.max_pool2d\cf9 \strokec9 (\cf4 \strokec4 F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .conv1\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )),\cf4 \strokec4  \cf6 \strokec6 2\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        x = F.max_pool2d\cf9 \strokec9 (\cf4 \strokec4 F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .conv2\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )),\cf4 \strokec4  \cf6 \strokec6 2\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        x = x.view\cf9 \strokec9 (\cf6 \strokec6 -1\cf9 \strokec9 ,\cf4 \strokec4  \cf11 \strokec11 self\cf4 \strokec4 .num_flat_features\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cb3        x = F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .fc1\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cb3        x = F.relu\cf9 \strokec9 (\cf11 \strokec11 self\cf4 \strokec4 .fc2\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cb3        x = \cf11 \strokec11 self\cf4 \strokec4 .fc3\cf9 \strokec9 (\cf4 \strokec4 x\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        \cf5 \strokec5 return\cf4 \strokec4  x\cb1 \
\cb3    \cf7 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 num_flat_features\cf4 \strokec4 (\cf11 \strokec11 self\cf4 \strokec4 , \cf11 \strokec11 x\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3        x_size = x.size\cf9 \strokec9 ()[\cf6 \strokec6 1\cf9 \strokec9 :]\cf4 \cb1 \strokec4 \
\cb3        num = \cf6 \strokec6 1\cf4 \cb1 \strokec4 \
\cb3        \cf5 \strokec5 for\cf4 \strokec4  n \cf12 \strokec12 in\cf4 \strokec4  x_size\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3            num *= n\cb1 \
\cb3        \cf5 \strokec5 return\cf4 \strokec4  num\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 load_data\cf4 \strokec4 ()\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    transform = transforms.Compose\cf9 \strokec9 ([\cf4 \cb1 \strokec4 \
\cb3        transforms.ToTensor\cf9 \strokec9 (),\cf4 \cb1 \strokec4 \
\cb3        transforms.Normalize\cf9 \strokec9 ((\cf6 \strokec6 0.5\cf9 \strokec9 ,),\cf4 \strokec4  \cf9 \strokec9 (\cf6 \strokec6 0.5\cf9 \strokec9 ,))\cf4 \strokec4   \cf2 \strokec2 # Adjust normalization for Fashion-MNIST\cf4 \cb1 \strokec4 \
\cb3    \cf9 \strokec9 ])\cf4 \cb1 \strokec4 \
\cb3    train_set = tv.datasets.FashionMNIST\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cb3        root=\cf13 \strokec13 './data'\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        train=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        download=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        transform=transform\cb1 \
\cb3    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    train_loader = torch.utils.data.DataLoader\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cb3        train_set\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        batch_size=train_batch_size\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        shuffle=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        num_workers=\cf6 \strokec6 2\cf4 \cb1 \strokec4 \
\cb3    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    test_set = tv.datasets.FashionMNIST\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cb3        root=\cf13 \strokec13 './data'\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        train=\cf7 \strokec7 False\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        download=\cf7 \strokec7 True\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        transform=transform\cb1 \
\cb3    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    test_loader = torch.utils.data.DataLoader\cf9 \strokec9 (\cf4 \cb1 \strokec4 \
\cb3        test_set\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        batch_size=test_batch_size\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        shuffle=\cf7 \strokec7 False\cf9 \strokec9 ,\cf4 \cb1 \strokec4 \
\cb3        num_workers=\cf6 \strokec6 2\cf4 \cb1 \strokec4 \
\cb3    \cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "Data loaded successfully..."\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    \cf5 \strokec5 return\cf4 \strokec4  train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 accuracy\cf4 \strokec4 (\cf11 \strokec11 model\cf4 \strokec4 , \cf11 \strokec11 x\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    \cf5 \strokec5 with\cf4 \strokec4  torch.no_grad\cf9 \strokec9 ():\cf4 \cb1 \strokec4 \
\cb3        correct = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cb3        total = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cb3        \cf5 \strokec5 for\cf4 \strokec4  data \cf12 \strokec12 in\cf4 \strokec4  x\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3            images\cf9 \strokec9 ,\cf4 \strokec4  labels = data\cb1 \
\cb3            outputs = model\cf9 \strokec9 (\cf4 \strokec4 images\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3            _\cf9 \strokec9 ,\cf4 \strokec4  predicted = torch.\cf10 \strokec10 max\cf9 \strokec9 (\cf4 \strokec4 outputs.data\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 1\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3            total += labels.size\cf9 \strokec9 (\cf6 \strokec6 0\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3            correct += \cf9 \strokec9 (\cf4 \strokec4 predicted == labels\cf9 \strokec9 )\cf4 \strokec4 .\cf10 \strokec10 sum\cf9 \strokec9 ()\cf4 \strokec4 .item\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cb3        \cf5 \strokec5 return\cf4 \strokec4  \cf9 \strokec9 (\cf6 \strokec6 100\cf4 \strokec4  * correct / total\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 train\cf4 \strokec4 (\cf11 \strokec11 train_loader\cf4 \strokec4 , \cf11 \strokec11 test_loader\cf4 \strokec4 , \cf11 \strokec11 model\cf4 \strokec4 , \cf11 \strokec11 criterion\cf4 \strokec4 , \cf11 \strokec11 optimizer\cf4 \strokec4 , \cf11 \strokec11 epoch\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    model.train\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3    running_loss = \cf6 \strokec6 0\cf4 \cb1 \strokec4 \
\cb3    \cf5 \strokec5 for\cf4 \strokec4  i\cf9 \strokec9 ,\cf4 \strokec4  data \cf12 \strokec12 in\cf4 \strokec4  \cf10 \strokec10 enumerate\cf9 \strokec9 (\cf4 \strokec4 train_loader\cf9 \strokec9 ,\cf4 \strokec4  \cf6 \strokec6 0\cf9 \strokec9 ):\cf4 \cb1 \strokec4 \
\cb3        inputs\cf9 \strokec9 ,\cf4 \strokec4  labels = data\cb1 \
\cb3        optimizer.zero_grad\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3        outputs = model\cf9 \strokec9 (\cf4 \strokec4 inputs\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        loss = criterion\cf9 \strokec9 (\cf4 \strokec4 outputs\cf9 \strokec9 ,\cf4 \strokec4  labels\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        loss.backward\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3        optimizer.step\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cb3        running_loss += loss.item\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3        \cf5 \strokec5 if\cf4 \strokec4  i % \cf6 \strokec6 200\cf4 \strokec4  == \cf6 \strokec6 199\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\cb3            \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "[epoch %d, iter %5d] loss: %.3f"\cf4 \strokec4  % \cf9 \strokec9 (\cf4 \strokec4 epoch+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  i+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  running_loss / \cf6 \strokec6 200\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cb3            running_loss = \cf6 \strokec6 0.0\cf4 \cb1 \strokec4 \
\cb3    train_acc = accuracy\cf9 \strokec9 (\cf4 \strokec4 model\cf9 \strokec9 ,\cf4 \strokec4  train_loader\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    test_acc = accuracy\cf9 \strokec9 (\cf4 \strokec4 model\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    \cf10 \strokec10 print\cf9 \strokec9 (\cf13 \strokec13 "epoch %d: train_acc %.3f, test_acc %.3f"\cf4 \strokec4  % \cf9 \strokec9 (\cf4 \strokec4 epoch+\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc\cf9 \strokec9 ))\cf4 \cb1 \strokec4 \
\cb3    \cf5 \strokec5 return\cf4 \strokec4  train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 def\cf4 \strokec4  \cf10 \strokec10 display\cf4 \strokec4 (\cf11 \strokec11 train_acc\cf4 \strokec4 , \cf11 \strokec11 test_acc\cf4 \strokec4 )\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    fig\cf9 \strokec9 ,\cf4 \strokec4  ax = plt.subplots\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3    ax.plot\cf9 \strokec9 (\cf10 \strokec10 range\cf9 \strokec9 (\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  \cf10 \strokec10 len\cf9 \strokec9 (\cf4 \strokec4 train_acc\cf9 \strokec9 )\cf4 \strokec4  + \cf6 \strokec6 1\cf9 \strokec9 ),\cf4 \strokec4  train_acc\cf9 \strokec9 ,\cf4 \strokec4  color=\cf13 \strokec13 'r'\cf9 \strokec9 ,\cf4 \strokec4  label=\cf13 \strokec13 'train_acc'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    ax.plot\cf9 \strokec9 (\cf10 \strokec10 range\cf9 \strokec9 (\cf6 \strokec6 1\cf9 \strokec9 ,\cf4 \strokec4  \cf10 \strokec10 len\cf9 \strokec9 (\cf4 \strokec4 test_acc\cf9 \strokec9 )\cf4 \strokec4  + \cf6 \strokec6 1\cf9 \strokec9 ),\cf4 \strokec4  test_acc\cf9 \strokec9 ,\cf4 \strokec4  color=\cf13 \strokec13 'b'\cf9 \strokec9 ,\cf4 \strokec4  label=\cf13 \strokec13 'test_acc'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    ax.legend\cf9 \strokec9 (\cf4 \strokec4 loc=\cf13 \strokec13 'lower right'\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3    plt.show\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 if\cf4 \strokec4  \cf11 \strokec11 __name__\cf4 \strokec4  == \cf13 \strokec13 '__main__'\cf9 \strokec9 :\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3    \cf2 \strokec2 # input Fashion-MNIST\cf4 \cb1 \strokec4 \
\cb3    train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader = load_data\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3    \cf2 \strokec2 # new model\cf4 \cb1 \strokec4 \
\cb3    net = Net\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\
\cb3    \cf2 \strokec2 # training\cf4 \cb1 \strokec4 \
\cb3    learning_rate = \cf6 \strokec6 0.001\cf4 \cb1 \strokec4 \
\cb3    momentum = \cf6 \strokec6 0.9\cf4 \cb1 \strokec4 \
\cb3    max_epoch = \cf6 \strokec6 20\cf4 \cb1 \strokec4 \
\cb3    criterion = nn.CrossEntropyLoss\cf9 \strokec9 ()\cf4 \cb1 \strokec4 \
\cb3    optimizer = optim.Adam\cf9 \strokec9 (\cf4 \strokec4 net.parameters\cf9 \strokec9 (),\cf4 \strokec4  lr=learning_rate\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\cb3    train_acc = \cf9 \strokec9 []\cf4 \cb1 \strokec4 \
\cb3    test_acc = \cf9 \strokec9 []\cf4 \cb1 \strokec4 \
\cb3    \cf5 \strokec5 for\cf4 \strokec4  epoch \cf12 \strokec12 in\cf4 \strokec4  \cf10 \strokec10 range\cf9 \strokec9 (\cf4 \strokec4 max_epoch\cf9 \strokec9 ):\cf4 \cb1 \strokec4 \
\cb3        train_acc_t\cf9 \strokec9 ,\cf4 \strokec4  test_acc_t = train\cf9 \strokec9 (\cf4 \strokec4 train_loader\cf9 \strokec9 ,\cf4 \strokec4  test_loader\cf9 \strokec9 ,\cf4 \strokec4  net\cf9 \strokec9 ,\cf4 \strokec4  criterion\cf9 \strokec9 ,\cf4 \strokec4  optimizer\cf9 \strokec9 ,\cf4 \strokec4  epoch\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        train_acc.append\cf9 \strokec9 (\cf4 \strokec4 train_acc_t\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\cb3        test_acc.append\cf9 \strokec9 (\cf4 \strokec4 test_acc_t\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
\
\cb3    display\cf9 \strokec9 (\cf4 \strokec4 train_acc\cf9 \strokec9 ,\cf4 \strokec4  test_acc\cf9 \strokec9 )\cf4 \cb1 \strokec4 \
}
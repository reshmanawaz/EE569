{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red89\green156\blue62;\red23\green23\blue23;\red202\green202\blue202;
\red183\green111\blue179;\red167\green197\blue152;\red70\green137\blue204;\red67\green192\blue160;\red212\green212\blue212;
\red212\green214\blue154;\red140\green211\blue254;\red113\green184\blue255;\red194\green126\blue101;}
{\*\expandedcolortbl;;\cssrgb\c41569\c66275\c30980;\cssrgb\c11765\c11765\c11765;\cssrgb\c83137\c83137\c83137;
\cssrgb\c77255\c52549\c75294;\cssrgb\c70980\c80784\c65882;\cssrgb\c33725\c61176\c83922;\cssrgb\c30588\c78824\c69020;\cssrgb\c86275\c86275\c86275;
\cssrgb\c86275\c86275\c66667;\cssrgb\c61176\c86275\c99608;\cssrgb\c50980\c77647\c100000;\cssrgb\c80784\c56863\c47059;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
# EE569 Homework Assignment #5 Sample Code\cf4 \cb1 \
\cf2 \cb3 # requirements: python3 + pytorch\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 import\cf4  torch\cb1 \
\cf5 \cb3 import\cf4  torch.nn \cf5 as\cf4  nn\cb1 \
\cf5 \cb3 import\cf4  torch.nn.functional \cf5 as\cf4  F\cb1 \
\cf5 \cb3 import\cf4  torch.optim \cf5 as\cf4  optim\cb1 \
\
\cf5 \cb3 import\cf4  torchvision \cf5 as\cf4  tv\cb1 \
\cf5 \cb3 import\cf4  torchvision.transforms \cf5 as\cf4  transforms\cb1 \
\
\cf5 \cb3 import\cf4  matplotlib.pyplot \cf5 as\cf4  plt\cb1 \
\cf5 \cb3 import\cf4  numpy \cf5 as\cf4  np\cb1 \
\cf5 \cb3 import\cf4  math\cb1 \
\cf5 \cb3 import\cf4  os\cb1 \
\
\cb3 train_batch_size=\cf6 64\cf4 \cb1 \
\cb3 test_batch_size=\cf6 1000\cf4 \cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 class\cf4  \cf8 Net\cf4 (\cf8 nn\cf4 .\cf8 Module\cf4 )\cf9 :\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf7 def\cf4  \cf10 __init__\cf4 (\cf11 self\cf4 )\cf9 :\cf4 \cb1 \
\cb3         super\cf9 (\cf4 Net\cf9 ,\cf11 self\cf9 )\cf4 .\cf10 __init__\cf9 ()\cf4 \cb1 \
\cb3         \cf11 self\cf4 .conv1=nn.Conv2d\cf9 (\cf6 1\cf9 ,\cf6 6\cf9 ,\cf6 5\cf9 ,\cf4 stride=\cf6 1\cf9 ,\cf4 padding=\cf6 2\cf9 )\cf4 \cb1 \
\cb3         \cf11 self\cf4 .conv2=nn.Conv2d\cf9 (\cf6 6\cf9 ,\cf6 16\cf9 ,\cf6 5\cf9 ,\cf4 stride=\cf6 1\cf9 ,\cf4 padding=\cf6 0\cf9 )\cf4 \cb1 \
\cb3         \cf11 self\cf4 .fc1=nn.Linear\cf9 (\cf6 16\cf4 *\cf6 5\cf4 *\cf6 5\cf9 ,\cf6 120\cf9 )\cf4 \cb1 \
\cb3         \cf11 self\cf4 .fc2=nn.Linear\cf9 (\cf6 120\cf9 ,\cf6 84\cf9 )\cf4 \cb1 \
\cb3         \cf11 self\cf4 .fc3=nn.Linear\cf9 (\cf6 84\cf9 ,\cf6 10\cf9 )\cf4 \cb1 \
\cb3     \cf7 def\cf4  \cf10 forward\cf4 (\cf11 self\cf4 ,\cf11 x\cf4 )\cf9 :\cf4 \cb1 \
\cb3         x=F.max_pool2d\cf9 (\cf4 F.relu\cf9 (\cf11 self\cf4 .conv1\cf9 (\cf4 x\cf9 )),\cf6 2\cf9 )\cf4 \cb1 \
\cb3         x=F.max_pool2d\cf9 (\cf4 F.relu\cf9 (\cf11 self\cf4 .conv2\cf9 (\cf4 x\cf9 )),\cf6 2\cf9 )\cf4 \cb1 \
\cb3         x=x.view\cf9 (\cf6 -1\cf9 ,\cf11 self\cf4 .num_flat_features\cf9 (\cf4 x\cf9 ))\cf4 \cb1 \
\cb3         x=F.relu\cf9 (\cf11 self\cf4 .fc1\cf9 (\cf4 x\cf9 ))\cf4 \cb1 \
\cb3         x=F.relu\cf9 (\cf11 self\cf4 .fc2\cf9 (\cf4 x\cf9 ))\cf4 \cb1 \
\cb3         x=\cf11 self\cf4 .fc3\cf9 (\cf4 x\cf9 )\cf4 \cb1 \
\cb3         \cf5 return\cf4  x\cb1 \
\cb3     \cf7 def\cf4  \cf10 num_flat_features\cf4 (\cf11 self\cf4 ,\cf11 x\cf4 )\cf9 :\cf4 \cb1 \
\cb3         \cf2 #x is a 4D tensor\cf4 \cb1 \
\cb3         x_size=x.size\cf9 ()[\cf6 1\cf9 :]\cf4 \cb1 \
\cb3         num=\cf6 1\cf4 \cb1 \
\cb3         \cf5 for\cf4  n \cf12 in\cf4  x_size\cf9 :\cf4 \cb1 \
\cb3             num*=n\cb1 \
\cb3         \cf5 return\cf4  num\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 def\cf4  \cf10 load_data\cf4 ()\cf9 :\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     transform=transforms.Compose\cf9 (\cf4 \cb1 \
\cb3         \cf9 [\cf4 transforms.ToTensor\cf9 (),\cf4 \cb1 \
\cb3         transforms.Normalize\cf9 ((\cf6 0.1307\cf9 ,),\cf4  \cf9 (\cf6 0.3081\cf9 ,))])\cf4 \cb1 \
\cb3     train_set=tv.datasets.MNIST\cf9 (\cf4 \cb1 \
\cb3         root=\cf13 './data'\cf9 ,\cf4 \cb1 \
\cb3         train=\cf7 True\cf9 ,\cf4 \cb1 \
\cb3         download=\cf7 True\cf9 ,\cf4 \cb1 \
\cb3         transform=transform\cb1 \
\cb3         \cf9 )\cf4 \cb1 \
\cb3     train_loader=torch.utils.data.DataLoader\cf9 (\cf4 \cb1 \
\cb3         train_set\cf9 ,\cf4 \cb1 \
\cb3         batch_size=train_batch_size\cf9 ,\cf4 \cb1 \
\cb3         shuffle=\cf7 True\cf9 ,\cf4 \cb1 \
\cb3         num_workers=\cf6 2\cf9 )\cf4 \cb1 \
\cb3     test_set=tv.datasets.MNIST\cf9 (\cf4 \cb1 \
\cb3         root=\cf13 './data'\cf9 ,\cf4 \cb1 \
\cb3         train=\cf7 False\cf9 ,\cf4 \cb1 \
\cb3         download=\cf7 True\cf9 ,\cf4 \cb1 \
\cb3         transform=transform\cb1 \
\cb3         \cf9 )\cf4 \cb1 \
\cb3     test_loader=torch.utils.data.DataLoader\cf9 (\cf4 \cb1 \
\cb3         test_set\cf9 ,\cf4 \cb1 \
\cb3         batch_size=test_batch_size\cf9 ,\cf4 \cb1 \
\cb3         shuffle=\cf7 False\cf9 ,\cf4 \cb1 \
\cb3         num_workers=\cf6 2\cf9 )\cf4 \cb1 \
\cb3     \cf10 print\cf9 (\cf13 "data loaded successfully..."\cf9 )\cf4 \cb1 \
\cb3     \cf5 return\cf4  train_loader\cf9 ,\cf4 test_loader\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 def\cf4  \cf10 accuracy\cf4 (\cf11 model\cf4 ,\cf11 x\cf4 ,\cf11 neg\cf4 =\cf7 False\cf4 )\cf9 :\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf5 with\cf4  torch.no_grad\cf9 ():\cf4 \cb1 \
\cb3         correct=\cf6 0\cf4 \cb1 \
\cb3         total=\cf6 0\cf4 \cb1 \
\cb3         class_correct = \cf8 list\cf9 (\cf6 0\cf4 . \cf5 for\cf4  i \cf12 in\cf4  \cf10 range\cf9 (\cf6 10\cf9 ))\cf4 \cb1 \
\cb3         class_total = \cf8 list\cf9 (\cf6 0\cf4 . \cf5 for\cf4  i \cf12 in\cf4  \cf10 range\cf9 (\cf6 10\cf9 ))\cf4 \cb1 \
\cb3         \cf5 for\cf4  data \cf12 in\cf4  x\cf9 :\cf4 \cb1 \
\cb3             images\cf9 ,\cf4 labels=data\cb1 \
\cb3             \cf5 if\cf4  neg\cf9 :\cf4 \cb1 \
\cb3               images=-images\cb1 \
\cb3             images\cf9 ,\cf4 labels=images\cf9 ,\cf4  labels\cb1 \
\cb3             outputs=model\cf9 (\cf4 images\cf9 )\cf4 \cb1 \
\cb3             _\cf9 ,\cf4 predicted=torch.\cf10 max\cf9 (\cf4 outputs.data\cf9 ,\cf6 1\cf9 )\cf4 \cb1 \
\cb3             total+=labels.size\cf9 (\cf6 0\cf9 )\cf4 \cb1 \
\cb3             correct+=\cf9 (\cf4 predicted==labels\cf9 )\cf4 .\cf10 sum\cf9 ()\cf4 .item\cf9 ()\cf4 \cb1 \
\
\cb3         \cf5 return\cf4  \cf9 (\cf6 100\cf4  * correct / total\cf9 )\cf4 \cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 def\cf4  \cf10 train\cf4 (\cf11 train_loader\cf4 , \cf11 test_loader\cf4 , \cf11 model\cf4 , \cf11 criterion\cf4 , \cf11 optimizer\cf4 ,\cf11 epoch\cf4 )\cf9 :\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     model.train\cf9 ()\cf4 \cb1 \
\cb3     running_loss=\cf6 0\cf4 \cb1 \
\cb3     \cf5 for\cf4  i\cf9 ,\cf4 data \cf12 in\cf4  \cf10 enumerate\cf9 (\cf4 train_loader\cf9 ,\cf6 0\cf9 ):\cf4 \cb1 \
\cb3         inputs\cf9 ,\cf4 labels=data\cb1 \
\cb3         inputs\cf9 ,\cf4 labels=inputs\cf9 ,\cf4  labels\cb1 \
\cb3         optimizer.zero_grad\cf9 ()\cf4 \cb1 \
\cb3         outputs=net\cf9 (\cf4 inputs\cf9 )\cf4 \cb1 \
\cb3         loss=criterion\cf9 (\cf4 outputs\cf9 ,\cf4 labels\cf9 )\cf4 \cb1 \
\cb3         loss.backward\cf9 ()\cf4 \cb1 \
\cb3         optimizer.step\cf9 ()\cf4 \cb1 \
\
\cb3         \cf2 # print statistics\cf4 \cb1 \
\cb3         running_loss+=loss.item\cf9 ()\cf4 \cb1 \
\cb3         \cf5 if\cf4  i%\cf6 200\cf4 ==\cf6 199\cf9 :\cf4 \cb1 \
\cb3             \cf10 print\cf9 (\cf13 "[epoch %d, iter %5d] loss: %.3f"\cf4 %\cf9 (\cf4 epoch+\cf6 1\cf9 ,\cf4 i+\cf6 1\cf9 ,\cf4 running_loss/\cf6 200\cf9 ))\cf4 \cb1 \
\cb3             running_loss=\cf6 0.0\cf4 \cb1 \
\cb3     train_acc=accuracy\cf9 (\cf4 model\cf9 ,\cf4 train_loader\cf9 )\cf4 \cb1 \
\cb3     test_acc=accuracy\cf9 (\cf4 model\cf9 ,\cf4 test_loader\cf9 )\cf4 \cb1 \
\cb3     \cf10 print\cf9 (\cf13 "epoch %d: train_acc %.3f, test_acc %.3f"\cf4 %\cf9 (\cf4 epoch+\cf6 1\cf9 ,\cf4 train_acc\cf9 ,\cf4 test_acc\cf9 ))\cf4 \cb1 \
\cb3     \cf5 return\cf4  train_acc\cf9 ,\cf4 test_acc\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 def\cf4  \cf10 display\cf4 (\cf11 train_acc\cf4 ,\cf11 test_acc\cf4 )\cf9 :\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     fig\cf9 ,\cf4 ax=plt.subplots\cf9 ()\cf4 \cb1 \
\cb3     ax.plot\cf9 (\cf10 range\cf9 (\cf6 1\cf9 ,\cf10 len\cf9 (\cf4 train_acc\cf9 )\cf4 +\cf6 1\cf9 ),\cf4 train_acc\cf9 ,\cf4 color=\cf13 'r'\cf9 ,\cf4 label=\cf13 'train_acc'\cf9 )\cf4 \cb1 \
\cb3     ax.plot\cf9 (\cf10 range\cf9 (\cf6 1\cf9 ,\cf10 len\cf9 (\cf4 test_acc\cf9 )\cf4 +\cf6 1\cf9 ),\cf4 test_acc\cf9 ,\cf4 color=\cf13 'b'\cf9 ,\cf4 label=\cf13 'test_acc'\cf9 )\cf4 \cb1 \
\cb3     ax.legend\cf9 (\cf4 loc=\cf13 'lower right'\cf9 )\cf4 \cb1 \
\cb3     plt.show\cf9 ()\cf4 \cb1 \
\
\cf5 \cb3 if\cf4  \cf11 __name__\cf4  == \cf13 '__main__'\cf9 :\cf4 \cb1 \
\cb3     \cf2 # input MNIST\cf4 \cb1 \
\cb3     train_loader\cf9 ,\cf4 test_loader=load_data\cf9 ()\cf4 \cb1 \
\cb3     \cf2 # new model\cf4 \cb1 \
\cb3     net=Net\cf9 ()\cf4 \cb1 \
\
\cb3     \cf2 # training\cf4 \cb1 \
\cb3     learning_rate=\cf6 0.01\cf4 \cb1 \
\cb3     momentum=\cf6 0.9\cf4 \cb1 \
\cb3     max_epoch=\cf6 10\cf4 \cb1 \
\cb3     criterion=nn.CrossEntropyLoss\cf9 ()\cf4 \cb1 \
\cb3     optimizer=optim.SGD\cf9 (\cf4 net.parameters\cf9 (),\cf4 lr=learning_rate\cf9 ,\cf4 momentum=momentum\cf9 )\cf4 \cb1 \
\
\cb3     train_acc=\cf9 []\cf4 \cb1 \
\cb3     test_acc=\cf9 []\cf4 \cb1 \
\cb3     \cf5 for\cf4  epoch \cf12 in\cf4  \cf10 range\cf9 (\cf4 max_epoch\cf9 ):\cf4 \cb1 \
\cb3         train_acc_t\cf9 ,\cf4 test_acc_t=train\cf9 (\cf4 train_loader\cf9 ,\cf4  test_loader\cf9 ,\cf4  net\cf9 ,\cf4  criterion\cf9 ,\cf4  optimizer\cf9 ,\cf4 epoch\cf9 )\cf4 \cb1 \
\cb3         train_acc.append\cf9 (\cf4 train_acc_t\cf9 )\cf4 \cb1 \
\cb3         test_acc.append\cf9 (\cf4 test_acc_t\cf9 )\cf4 \cb1 \
\
\cb3     display\cf9 (\cf4 train_acc\cf9 ,\cf4 test_acc\cf9 )}